{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"For hpc_v5.ipynb","provenance":[{"file_id":"1w3I-5upm6p-Qhgztc3NM52xzgKaG4fKM","timestamp":1658172083564}],"authorship_tag":"ABX9TyMPBvHP1Bnz4j78XVGK5bGR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from tensorflow import keras\n","#import torch\n","#from torch import nn\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import csv\n","from numpy import *\n","\n","from tensorflow.keras import layers\n","from tensorflow.keras import models\n","from IPython import display\n","\n","root_url = \"/users/yjia3/ml_risk_cycled/\"\n","root_url_data = root_url+\"DATA/\"\n","root_url_model = root_url+\"MODEL/\"\n","test_file_name=\"R500N300\"\n","model_name_0=\"RNN_\"+test_file_name\n","file_name=test_file_name\n","\n","channel = 7\n","features = [[0,1,2,3,4,5,6]]\n","# features = [[0,1,2],[0,1,2,3,4],[0,1,2,3],[0,1,2,3,5],[0,1,2,4],[0,1,2,4,6]]\n","# sigement_size=180\n","test_size = 0.1  #[CHANGE]\n","reference_resistance = 100\n","epochs = 200\n","batch_size = 128\n","repeated_time  =  5\n","smallest_size = 60\n","\n","# sigement_sizes=[60,120,180,300,600]\n","sigement_sizes=[120]\n","# sigement_sizes=[10, 20, 30, 60, 120, 300]\n","\n","for sigement_size in sigement_sizes:\n","\n","  print(sigement_size)\n","\n","  input0 = np.empty(shape=(0,channel,sigement_size))\n","  label = np.empty(shape=(0))\n","\n","  samples = np.loadtxt(open(root_url_data+file_name+\"T\"+str(sigement_size)+\"_S.csv\",\"rb\"),delimiter=\",\",skiprows=0)\n","  input0 = np.reshape(samples[:,0:sigement_size*channel],(len(samples),channel,sigement_size))\n","  label = samples[:,sigement_size*channel]\n","  input0 = input0.transpose(0,2,1)\n","\n","  for feature in features:\n","\n","    print(feature)\n","\n","    input = input0[:,:,feature]\n","    print(np.shape(input))\n","\n","    y0 = np.log(reference_resistance/1e6)\n","    y1 = np.log(reference_resistance/1e-1)\n","    label = (label-y0)/(y1-y0)\n","\n","    for repeat in range(repeated_time):\n","\n","      print(\"\")\n","      print(\"======================================================\")\n","      print(str(repeat)+\"/\"+str(repeated_time)+\" training\")\n","\n","      idx = np.random.RandomState(seed=repeat).permutation(len(label))\n","      input_ramdom = input[idx]\n","      label_ramdom = label[idx]\n","\n","      cut_idx = int(round((1-test_size) * len(label)))\n","      x_train, x_test = input_ramdom[:cut_idx], input_ramdom[cut_idx:]\n","      y_train, y_test = label_ramdom[:cut_idx], label_ramdom[cut_idx:]\n","\n","      norm_layer = layers.experimental.preprocessing.Normalization(axis=-1)\n","      adapt_data=input\n","      norm_layer.adapt(adapt_data)\n","\n","      if sigement_size < smallest_size:\n","  #      x_train = nn.functional.upsample(x_train, size=(x_train.shape[0],60,x_train.shape[2]), mode='linear', align_corners=True)\n","        x_train = layers.UpSampling1D(size=round(smallest_size/sigement_size))(x_train)    \n","      input_shape=x_train.shape[1:]\n","      print(np.shape(x_train))\n","\n","      model = models.Sequential([\n","          layers.Input(shape=input_shape),\n","          norm_layer,\n","\n","          layers.Conv1D(64, 2, activation='relu'),\n","          \n","          layers.Conv1D(64, 3, activation='relu'),\n","          layers.Conv1D(64, 3, activation='relu'),\n","          layers.Conv1D(64, 3, activation='relu'),\n","          layers.Conv1D(64, 3, activation='relu'),\n","          \n","          layers.Dropout(0.25),\n","          layers.Flatten(),\n","          layers.Dense(128, activation='relu'),\n","          layers.Dropout(0.5),\n","\n","          layers.Dense(1),\n","      ])\n","\n","      model.summary()\n","\n","      callbacks = [\n","          keras.callbacks.ModelCheckpoint(\n","              \"best_model.h5\", save_best_only=True, monitor=\"val_loss\"\n","          ),\n","          keras.callbacks.ReduceLROnPlateau(\n","              monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n","          ),\n","          # keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n","      ]\n","\n","      optimizer = keras.optimizers.RMSprop(learning_rate=0.001)\n","      \n","      model.compile(\n","          optimizer=optimizer,\n","          loss=\"mse\",\n","          metrics=[\"mae\",\"mse\"],\n","      )\n","\n","      history = model.fit(\n","          x_train,\n","          y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          callbacks=callbacks,\n","          validation_split=0.2,\n","          verbose=2\n","      )\n","\n","      model_name = model_name_0+\"T\"+str(sigement_size)+str(repeat)+str(feature)\n","      model.save(root_url_model+model_name)\n","\n","      metric = \"mse\"\n","      historyfile = open(root_url_model+model_name+\".csv\",\"w\", encoding='utf-8', newline='')\n","      writer = csv.writer(historyfile)\n","\n","      for step in range(len(history.history[metric])):\n","        writer.writerow([step,history.history[metric][step],history.history[\"val_\" + metric][step]])\n","      historyfile.close()\n","\n","      plt.figure()\n","      plt.plot(history.history[metric])\n","      plt.plot(history.history[\"val_\" + metric])\n","      plt.title(\"model \" + metric)\n","      plt.ylabel(metric, fontsize=\"large\")\n","      plt.xlabel(\"epoch\", fontsize=\"large\")\n","      plt.legend([\"train\", \"val\"], loc=\"best\")\n","      plt.savefig(root_url_model+model_name+\".png\")\n","      # plt.show()\n","      plt.close()"],"metadata":{"id":"icKbJry7wjgb"},"execution_count":null,"outputs":[]}]}