{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1C3UB4ahEu27jAqVHiDuCdi5EQpmeg2eJ","timestamp":1661976854487},{"file_id":"16oL7X6GdtTbFVFi8Ki5i3I2SnLkgpRQ9","timestamp":1658344389918},{"file_id":"1KTMDRDBJ6U57VgMbn8QtceIKsT7POMgD","timestamp":1658153892910},{"file_id":"1rAUn-UsLth5gd9DvryAchUNyfE4z5uUx","timestamp":1657226476742}],"collapsed_sections":[],"mount_file_id":"1rAUn-UsLth5gd9DvryAchUNyfE4z5uUx","authorship_tag":"ABX9TyPAa/52CzfnGhoLkI0cAFbw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from tensorflow import keras\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import csv\n","from numpy import *\n","import math\n","\n","from tensorflow.keras import layers\n","from tensorflow.keras import models\n","from IPython import display\n","\n","root_url = \"/users/yjia3/ml_risk_cycled/\"\n","root_url_data = root_url+\"DATA/\"\n","root_url_model = root_url+\"MODEL/V6/\"\n","test_file_name=\"R500N300\"\n","model_name_0=\"RNN_\"+test_file_name\n","file_name=test_file_name\n","\n","channel = 7\n","features = [[0,1,2,3,4,5,6]]\n","# features = [[0,1,2,3,4],[0,1,2,3],[0,1,2,3,5],[0,1,2,4],[0,1,2,4,6]]\n","\n","test_size = 0.1\n","sigement_sizes=[120]\n","# sigement_sizes=[60,120,180,300,600]\n","\n","smallest_size = 60\n","repeated_time = 5\n","\n","for sigement_size in sigement_sizes:\n","\n","  print(sigement_size)\n","  input0 = np.empty(shape=(0,channel,sigement_size))\n","  label = np.empty(shape=(0))\n","\n","  samples = np.loadtxt(open(root_url_data+file_name+\"T\"+str(sigement_size)+\"_S.csv\",\"rb\"),delimiter=\",\",skiprows=0)\n","  input0 = np.reshape(samples[:,0:sigement_size*channel],(len(samples),channel,sigement_size))\n","  label = samples[:,sigement_size*channel]\n","  input0 = input0.transpose(0,2,1)\n","\n","  reference_resistance = 100\n","  y0 = np.log(reference_resistance/1e6)\n","  y1 = np.log(reference_resistance/1e-1)\n","  label = (label-y0)/(y1-y0)\n","\n","  for feature in features:\n","\n","    print(feature)\n","\n","    input = input0[:,:,feature]\n","    print(np.shape(input))\n","\n","    for repeat in range(repeated_time):\n","\n","      print(str(repeat)+\"/\"+str(repeated_time)+\" testing\")\n","\n","      ouput_file_name=file_name+'T'+str(sigement_sizes[-1])+'T'+str(repeat)\n","      testfile = open(root_url_model+ouput_file_name+\".csv\",\"w\", encoding='utf-8', newline='')\n","      writer = csv.writer(testfile)\n","\n","      idx = np.random.RandomState(seed=repeat).permutation(len(label))\n","      input_ramdom = input[idx]\n","      label_ramdom = label[idx]\n","\n","      cut_idx = int(round((1-test_size) * len(label)))\n","      x_train, x_test = input_ramdom[:cut_idx], input_ramdom[cut_idx:]\n","      y_train, y_test = label_ramdom[:cut_idx], label_ramdom[cut_idx:]\n","\n","      if sigement_size < smallest_size:\n","        x_test = layers.UpSampling1D(size=round(smallest_size/sigement_size))(x_test)   \n","\n","      # input_shape=x_train.shape[1:]\n","      # print(np.shape(x_train))\n","\n","      model_name = model_name_0+\"T\"+str(sigement_size)+str(repeat)+\"_\"\n","      for feature0 in feature:\n","        model_name = model_name+str(feature0)\n","\n","      model = keras.models.load_model(root_url_model+model_name)\n","      # model.summary()\n","\n","      y_predictions = model.predict(x_test).flatten()\n","      \n","      number_test = len(y_predictions)\n","      l1 = 0\n","      l2 = 0\n","      for i in range(number_test):\n","\n","        current=x_test[i,:,2].flatten()\n","        #print(current)\n","        std_i=np.std(current)\n","        avg_i=np.mean(current)\n","\n","        C_current = 0\n","        Group = 1\n","\n","        if std_i/avg_i<0.01:\n","          Group = 0\n","        C_current = round(avg_i/3.2*10)/10\n","\n","        r_prediction = reference_resistance*math.exp(-y_predictions[i]*(y1-y0)-y0)\n","        r_test = reference_resistance*math.exp(-y_test[i]*(y1-y0)-y0)\n","\n","        writer.writerow([Group, std_i, avg_i,  C_current, y_test[i], y_predictions[i], r_prediction, r_test])\n","      \n","      testfile.close()     "],"metadata":{"id":"MtqKmDMr4Lwo"},"execution_count":null,"outputs":[]}]}